# LSP-EnSe√±as ‚Äì Reconocimiento de se√±as en video

Este proyecto permite reconocer se√±as de la **Lengua de Se√±as Peruana (LSP)** a partir de videos, utilizando:

- **MediaPipe Holistic** para extraer landmarks del cuerpo y manos.
- **TensorFlow LSTM** para aprender el movimiento en el tiempo.
- **OpenCV** para capturar y procesar video.
- **Google Colab** para entrenamiento del modelo.
- **Python** para correr el modelo en tiempo real desde webcam.

---

### üß† ¬øQu√© hace?

- Aprende se√±as a partir de videos cortos.
- Procesa los movimientos en secuencia (video, no solo im√°genes).
- Genera un modelo que identifica la se√±a con su probabilidad.

---

### üîß ¬øQu√© archivos incluye?

- `lsp_holistic_singtrad_LSTM.ipynb`: Notebook principal. Entrenas, eval√∫as y pruebas el modelo con tus videos.
- `sign_lstm_realtime.py`: Script para reconocimiento en vivo con webcam.
- Carpeta `SignProject/models/`:
  - `sign_model_lstm_v1.keras`: modelo entrenado en formato Keras.
  - `label_names.json`: lista de se√±as reconocidas por el modelo.

Todos estos archivos est√°n en este Drive:

üîó **Carpeta del proyecto (archivos listos para usar):**  
https://drive.google.com/drive/folders/1P367OVTz7mq8VLk544odZlAYIK1H9COv?usp=drive_link

---

### üõ†Ô∏è C√≥mo usar el Notebook

1. Abre `lsp_holistic_singtrad_LSTM.ipynb` en Google Colab.
2. Ejecuta las celdas paso a paso:
   - Montar el Drive.
   - Extraer landmarks con MediaPipe.
   - Crear dataset de secuencias.
   - Entrenar el modelo LSTM.
   - Evaluar y probar el modelo con tus propios videos.
3. El modelo final se guarda en `SignProject/models/`.

---

### üñ•Ô∏è C√≥mo reconocer se√±as en vivo

1. Aseg√∫rate de tener Python 3.9+ y estas librer√≠as:

pip install mediapipe opencv-python tensorflow numpy

2. Guarda la carpeta `SignProject/models/` junto al archivo `sign_lstm_realtime.py`.
3. Ejecuta el script:
python sign_lstm_realtime.py
4. En la ventana de c√°mara:
   - Haz una se√±a.
   - Presiona `R` para capturarla.
   - Se mostrar√° en pantalla la se√±a detectada con la confianza.

---

### ‚öôÔ∏è Tecnolog√≠as usadas

- MediaPipe Holistic (3D pose + manos).
- TensorFlow (LSTM para secuencias).
- OpenCV (captura de video).
- Google Colab (entrenamiento).
- Python 3.9+
- Aumentaci√≥n por espejado para control de mano dominante (opcional).

---

*Inteligencia Artificial aplicada a accesibilidad inclusiva.
